{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Homework\n",
    "\n",
    "> In case you don't get one option exactly, select the closest one \n",
    "\n",
    "For the homework, we'll be working with the _green_ taxi dataset located here:\n",
    "\n",
    "`https://github.com/DataTalksClub/nyc-tlc-data/releases/tag/green/download`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_download = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/tag/green/download'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "The goal will be to construct an ETL pipeline that loads the data, performs some transformations, and writes the data to a database (and Google Cloud!).\n",
    "\n",
    "- Create a new pipeline, call it `green_taxi_etl`\n",
    "- Add a data loader block and use Pandas to read data for the final quarter of 2020 (months `10`, `11`, `12`).\n",
    "  - You can use the same datatypes and date parsing methods shown in the course.\n",
    "  - `BONUS`: load the final three months using a for loop and `pd.concat`\n",
    "- Add a transformer block and perform the following:\n",
    "  - Remove rows where the passenger count is equal to 0 _or_ the trip distance is equal to zero.\n",
    "  - Create a new column `lpep_pickup_date` by converting `lpep_pickup_datetime` to a date.\n",
    "  - Rename columns in Camel Case to Snake Case, e.g. `VendorID` to `vendor_id`.\n",
    "  - Add three assertions:\n",
    "    - `vendor_id` is one of the existing values in the column (currently)\n",
    "    - `passenger_count` is greater than 0\n",
    "    - `trip_distance` is greater than 0\n",
    "- Using a Postgres data exporter (SQL or Python), write the dataset to a table called `green_taxi` in a schema `mage`. Replace the table if it already exists.\n",
    "- Write your data as Parquet files to a bucket in GCP, partioned by `lpep_pickup_date`. Use the `pyarrow` library!\n",
    "\n",
    "- Schedule your pipeline to run daily at 5AM UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd homework/02-workflow-orchestration\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Open [http://localhost:6789](http://localhost:6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline\n",
    "1. `+ New Pipeline > Standard (batch)`\n",
    "1. `Edit pipeline settinngs` rename to `green_taxi_etl`\n",
    "1. Add tag `dezoomcamp_homework_2`\n",
    "1. `Save pipeline settings`\n",
    "\n",
    "Edit pipeline\n",
    "1. Select `Edit pipeline` from sidebar\n",
    "1. `+ Data loader > Python > Generic (no template)` rename to `read_final_quarter_2020` -> `Save and add`\n",
    "\n",
    "Edit data loader\n",
    "```python\n",
    "@data_loader\n",
    "def load_data(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Template code for loading data from any source.\n",
    "\n",
    "    Returns:\n",
    "        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n",
    "    \"\"\"\n",
    "    url_download = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/'\n",
    "    year = 2020\n",
    "    months = [10, 11, 12]\n",
    "\n",
    "    #green_tripdata_{year}-{month}.csv.gz\n",
    "\n",
    "    # reduces memory usage in pandas\n",
    "    taxi_dtypes = {\n",
    "        'VendorID': pd.Int64Dtype(),\n",
    "        'RatecodeID':pd.Int64Dtype(),\n",
    "        'store_and_fwd_flag':str,\n",
    "        'PULocationID':pd.Int64Dtype(),\n",
    "        'DOLocationID':pd.Int64Dtype(),\n",
    "        'passenger_count': pd.Int64Dtype(),\n",
    "        'trip_distance': float,\n",
    "        'payment_type': pd.Int64Dtype(),\n",
    "        'fare_amount': float,\n",
    "        'extra':float,\n",
    "        'mta_tax':float,\n",
    "        'tip_amount':float,\n",
    "        'tolls_amount':float,\n",
    "        'ehail_fee': float,\n",
    "        'improvement_surcharge':float,\n",
    "        'total_amount': float,\n",
    "        'payment_type': pd.Int64Dtype(),\n",
    "        'trip_type': float,\n",
    "        'congestion_surcharge':float\n",
    "    }\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    for month in months:\n",
    "        url = os.path.join(\n",
    "            url_download,\n",
    "            f\"green_tripdata_{year}-{month}.csv.gz\"\n",
    "        )\n",
    "        print(url)\n",
    "        data_month = pd.read_csv(\n",
    "            url, sep=',', compression='gzip', dtype=taxi_dtypes, \n",
    "            parse_dates=['lpep_pickup_datetime', 'lpep_dropoff_datetime']\n",
    "        )\n",
    "        data = pd.concat([data, data_month], ignore_index=True)\n",
    "        print(data.shape)\n",
    "    return data\n",
    "```\n",
    "\n",
    "Add transformer\n",
    "1. `+ Transformer > Python > Generic (no template)` rename to `transform_drop_rows` -> `Save and add`\n",
    "```python\t\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    indices = ~(data['passenger_count'].eq(0) | data['trip_distance'].eq(0))\n",
    "    print(data.shape)\n",
    "    data = data[indices]\n",
    "    print(data.shape)\n",
    "    return data\n",
    "```\n",
    "\n",
    "Add transformer adding date column\n",
    "1. `+ Transformer > Python > Generic (no template)` rename to `transformer_add_date_col` -> `Save and add`\n",
    "```python\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date\n",
    "    return data\n",
    "```\n",
    "\n",
    "Add transformer for retrieving unique `VendorID` values\n",
    "1. `+ Transformer > Python > Generic (no template)` rename to `transform_check_vendorid` -> `Save and add`\n",
    "```python\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    print(data['VendorID'].unique())\n",
    "    return data\n",
    "```\n",
    "\n",
    "Add transformer for renaming columns from Camel Case to Snake Case\n",
    "1. `+ Transformer > Python > Generic (no template)` rename to `transform_rename_cols` -> `Save and add`\n",
    "```python\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    data.columns = data.columns.str.lower()\n",
    "    return data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "## Question 1. Data Loading\n",
    "\n",
    "Once the dataset is loaded, what's the shape of the data?\n",
    "\n",
    "* **266,855 rows x 20 columns**\n",
    "* 544,898 rows x 18 columns\n",
    "* 544,898 rows x 20 columns\n",
    "* 133,744 rows x 20 columns\n",
    "\n",
    "\n",
    "### Answer 1\n",
    "\n",
    "`266,855 rows x 20 columns`\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2. Data Transformation\n",
    "\n",
    "Upon filtering the dataset where the passenger count is greater than 0 _and_ the trip distance is greater than zero, how many rows are left?\n",
    "\n",
    "* 544,897 rows\n",
    "* 266,855 rows\n",
    "* **139,370 rows**\n",
    "* 266,856 rows\n",
    "\n",
    "### Answer 2\n",
    "\n",
    "`139,370 rows`\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3. Data Transformation\n",
    "\n",
    "Which of the following creates a new column `lpep_pickup_date` by converting `lpep_pickup_datetime` to a date?\n",
    "\n",
    "* `data = data['lpep_pickup_datetime'].date`\n",
    "* `data('lpep_pickup_date') = data['lpep_pickup_datetime'].date`\n",
    "* **`data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date`**\n",
    "* `data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt().date()`\n",
    "\n",
    "### Answer 3\n",
    "\n",
    "`data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date`\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4. Data Transformation\n",
    "\n",
    "What are the existing values of `VendorID` in the dataset?\n",
    "\n",
    "* 1, 2, or 3\n",
    "* **1 or 2**\n",
    "* 1, 2, 3, 4\n",
    "* 1\n",
    "\n",
    "### Answer 4\n",
    "\n",
    "`1 or 2`\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5. Data Transformation\n",
    "\n",
    "How many columns need to be renamed to snake case?\n",
    "\n",
    "* 3\n",
    "* 6\n",
    "* 2\n",
    "* **4**\n",
    "\n",
    "### Answer 5\n",
    "\n",
    "`4`\n",
    "\n",
    "---\n",
    "\n",
    "## Question 6. Data Exporting\n",
    "\n",
    "Once exported, how many partitions (folders) are present in Google Cloud?\n",
    "\n",
    "* **96**\n",
    "* 56\n",
    "* 67\n",
    "* 108\n",
    "\n",
    "### Answer 6\n",
    "\n",
    "`95`\n",
    "\n",
    "## Submitting the solutions\n",
    "\n",
    "* Form for submitting: https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2\n",
    "* Check the link above to see the due date\n",
    "  \n",
    "## Solution\n",
    "\n",
    "Will be added after the due date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
